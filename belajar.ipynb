{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(91934) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (319 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, jiter, distro, annotated-types, pydantic, openai, ollama\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.9.0 ollama-0.4.7 openai-1.66.3 pydantic-2.10.6 pydantic-core-2.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(92909) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.4.7)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.66.3)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=\"gpt-4o-mini\", \n",
    "                                          messages=[{\"role\": \"system\", \"content\": \"Siapa Presiden Indonesia.\"}], \n",
    "                                          max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BBdpFHWY3doNoaQmRRQuMkegIPJ0q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Presiden Indonesia per Oktober 2023 adalah Joko Widodo, yang mulai menjabat pada 20 Oktober 2014.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1742114397, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=27, prompt_tokens=12, total_tokens=39, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user asked for an example like the previous one about Prance's ibukota and now they're asking about Japan's ibukota.\n",
      "\n",
      "They might be learning Japanese or trying to find a straightforward answer. Since I can't provide real names because that would be inappropriate, I should explain what ibukota means in Japanese. \n",
      "\n",
      "I remember that ibukota refers to famous people or places named after another person. So, I need to list some well-known individuals from Japan and their respective ibukotas.\n",
      "\n",
      "I'll start with the most famous ones first: King Haruto II of Japan is a big name, followed by Emperor Meiji as he's often called the \"Lover of Heaven.\" There's also King Hiroshi Toyama who was a ruler before his passing. Oh, and King Shizuo Nara is another prominent figure.\n",
      "\n",
      "I should make sure to note that these are names, not real individuals because their lives have been cut off in history. I'll list each name with their ibukotas and explain briefly why they're famous just to give the user a clear idea.\n",
      "</think>\n",
      "\n",
      "Apabila kita mencari contoh ibukota日本 (nationality) dari berbagai place yang diinginkan, kita bisa membicarakan sebaganya berikut:\n",
      "\n",
      "1. **Kei Nara** – King Kei Nara II of Japan\n",
      "2. **Kunru估计为“大正”或“天保”，而 Emperor Meiji** (大正 Emperor or 天保君主) – Emperor Meiji, King Meiji\n",
      "3. **Kunru估计为“朝鮮”，而 King Sinica** (朝鮮王 or 齐天公) – King Sinica\n",
      "4. **Kei no Gaku** – King Kei no Gaku of Japan\n",
      "\n",
      "Setiap ibukota日本 (nationality) berbeda dan terlihat dari sepanjang waktu, jadi tidak semua mereka bisa dituliskan dalam satu tempat.\n"
     ]
    }
   ],
   "source": [
    "# Ollama: One-Shot Prompting\n",
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='deepseek-r1:1.5b',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'Contoh: Apa ibukota Prancis?'},\n",
    "        {'role': 'assistant', 'content': 'Ibukota Prancis adalah Paris.'},\n",
    "        {'role': 'user', 'content': 'Apa ibukota Jepang?'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2:3b\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    max_tokens=100\n",
    "    # other params ...\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Maaf, saya tidak memiliki informasi tentang presiden terbaru atau penggantinya. Namun, berdasarkan informasi yang tersedia hingga tahun 2023, Presiden Republik Indonesia pada saat itu adalah Joko Widodo.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b', 'created_at': '2025-03-16T13:44:17.693061Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6631400750, 'load_duration': 1079678084, 'prompt_eval_count': 31, 'prompt_eval_duration': 2804000000, 'eval_count': 52, 'eval_duration': 2738000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-0a3a1c1f-ff6c-4ff5-b636-f7a75e945bef-0', usage_metadata={'input_tokens': 31, 'output_tokens': 52, 'total_tokens': 83})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Siapa presiden Indonesia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning 23.03.25\n",
    "## Using Groq Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nIbukota Indonesia adalah **Jakarta**.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 10, 'total_tokens': 26, 'completion_time': 0.058181818, 'prompt_time': 0.005980504, 'queue_time': 0.34308113, 'total_time': 0.064162322}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-12d4e2b6-9d02-4679-a154-cd57b84fa7a6-0', usage_metadata={'input_tokens': 10, 'output_tokens': 16, 'total_tokens': 26})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'deepseek-r1-distill-llama-70b'\n",
    "ChatGroq(model = model).invoke(\"Apa ibukota Indonesia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama3-70b-8192'\n",
    "llm_groq = ChatGroq(model=model, temperature=1.0) #.invoke(\"Apa ibukota Indonesia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classification_prompt = \"\"\"\n",
    "Apakah penulis ulasan berikut ini sedang mengekspresikan kemarahan?\\\n",
    "Ulasan ini dibatasi dengan tanda kutip tiga.\\\n",
    "Berikan jawaban Anda sebagai ya atau tidak.\n",
    "\n",
    "Tolong jangan memberikan penjelasan, dan jawab dengan satu kata\n",
    "\n",
    "Teks ulasan: \\\"\\\"\\\"{context}\\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(input_variables=[\"context\"], template = my_classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contoh_ulasan = \"\"\"\n",
    "Judul Ulasan: Produk Berkualitas, Sesuai Ekspektasi\n",
    "\n",
    "Rating: ★★★★☆\n",
    "\n",
    "Ulasan:\n",
    "Halo DTSense, saya baru saja membeli body-lotion dari Tokolapak.com, dan secara keseluruhan, saya sangat puas dengan pembelian ini. Produk ini hadir dengan kualitas yang sangat baik dan sesuai dengan deskripsi yang tertera di halaman produk.\n",
    "\n",
    "Kelebihan:\n",
    "Kualitas bahan: Materialnya kokoh dan terlihat tahan lama, persis seperti yang saya harapkan.\n",
    "Fungsi: Semua fitur produk berfungsi dengan baik. Sangat mudah digunakan, dan saya tidak mengalami masalah selama penggunaannya.\n",
    "Pengiriman: Pengiriman cepat dan barang dikemas dengan baik, tidak ada kerusakan selama pengiriman.\n",
    "Harga: Harga cukup terjangkau untuk kualitas yang diberikan, jadi menurut saya ini adalah nilai yang baik.\n",
    "Kekurangan:\n",
    "\n",
    "Warna: Warna produk sedikit berbeda dari yang ditampilkan di foto. Dalam deskripsi tertulis warna biru tua, tapi yang saya terima sedikit lebih terang.\n",
    "Petunjuk penggunaan: Manualnya kurang jelas, terutama untuk orang yang baru pertama kali menggunakan produk ini.\n",
    "Secara keseluruhan, saya puas dengan pembelian ini dan akan mempertimbangkan untuk membeli produk lain dari toko yang sama di masa mendatang. Rekomendasi untuk mereka yang mencari produk dengan kualitas baik dan harga yang wajar.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tidak', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 435, 'total_tokens': 438, 'completion_time': 0.031591253, 'prompt_time': 0.013895302, 'queue_time': 0.248929623, 'total_time': 0.045486555}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-c7b56928-cef5-44f1-b60f-b21b70f999b2-0', usage_metadata={'input_tokens': 435, 'output_tokens': 3, 'total_tokens': 438})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(prompt.format(context=contoh_ulasan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text elaboration and expansion\n",
    "review_skin_care = \"\"\"\n",
    "Rating: ⭐ 1/5\n",
    "\n",
    "Judul: Sangat Kecewa dengan Produk Ini!\n",
    "\n",
    "Halo DTSense, Saya membeli produk skincare ini dari Tokolapak.com dengan harapan bisa memperbaiki kondisi kulit saya. Sayangnya, hasilnya sangat mengecewakan! Setelah seminggu pemakaian, kulit saya justru menjadi kering dan iritasi. Ada kemerahan di beberapa bagian wajah, terutama di sekitar pipi dan dahi.\n",
    "\n",
    "Selain itu, tekstur produknya lengket dan tidak nyaman saat diaplikasikan. Butuh waktu lama untuk menyerap, dan aromanya sangat menyengat, benar-benar tidak enak. Saya sudah mencoba mengikuti petunjuk pemakaian, tetapi hasilnya malah memperburuk kondisi kulit.\n",
    "\n",
    "Yang lebih mengecewakan, layanan pelanggan Tokolapak.com tidak responsif sama sekali. Saya mencoba menghubungi untuk mengajukan pengembalian produk, tetapi tidak ada tanggapan. Benar-benar pengalaman belanja yang buruk, tidak akan membeli produk skincare dari sini lagi!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_check_sentiment_prompt = \"\"\"\n",
    "Anda adalah asisten AI layanan pelanggan.\n",
    "Tugas Anda adalah mengirim balasan email ke pelanggan yang Anda hargai.\n",
    "Dengan email pelanggan yang dibatasi oleh tanda kutip tiga, \\\n",
    "Buat balasan untuk berterima kasih kepada pelanggan atas ulasan mereka.\n",
    "Jika sentimennya positif atau netral, berterima kasihlah atas \\\n",
    "ulasan mereka.\n",
    "Jika sentimennya negatif, minta maaf dan sarankan agar \\\n",
    "mereka dapat menghubungi layanan pelanggan.\n",
    "Pastikan untuk menggunakan detail spesifik dari ulasan.\n",
    "Tulis dengan nada yang ringkas dan profesional.\n",
    "Tandatangani email sebagai \"asisten AI\".\n",
    "Customer review: \\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "Tolong jawab dengan bahasa yang sama dengan ulasan pelanggan.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_review = PromptTemplate(input_variables=[\"text\"], template = expand_check_sentiment_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Subject: Re: Sangat Kecewa dengan Produk Ini!\\n\\nDear [Pelanggan],\\n\\nTerima kasih atas waktu Anda untuk berbagi pengalaman Anda dengan produk skincare kami. Kami sangat menyesal bahwa produk kami tidak memenuhi harapan Anda dan malah menyebabkan kulit Anda kering dan iritasi.\\n\\nKami memahami bahwa tekstur produk yang lengket dan aromanya yang menyengat tidak nyaman untuk Anda. Kami juga khawatir tentang kemerahan di pipi dan dahi yang Anda alami.\\n\\nKami sangat menyesal bahwa layanan pelanggan Tokolapak.com tidak responsif terhadap kebutuhan Anda. Kami akan segera menghubungi mereka untuk memastikan bahwa masalah ini diselesaikan.\\n\\nJika Anda memerlukan bantuan lebih lanjut atau memiliki pertanyaan, silakan tidak ragu untuk menghubungi kami. Kami ingin membantu Anda mencari solusi untuk masalah Anda.\\n\\nTerima kasih lagi atas umpan balik Anda. Kami akan melakukan upaya terbaik untuk memperbaiki produk dan layanan kami.\\n\\nBest regards,\\nAsisten AI', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 446, 'total_tokens': 693, 'completion_time': 0.825419106, 'prompt_time': 0.014591888, 'queue_time': 0.24801526000000002, 'total_time': 0.840010994}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-40181944-492b-4d9a-a5fc-0352aed00107-0', usage_metadata={'input_tokens': 446, 'output_tokens': 247, 'total_tokens': 693})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(prompt_review.format(text=review_skin_care))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- sedikit check kapabilitas tanpa ada memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Halo David! Selamat datang! Bagaimana kabar hari ini?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 15, 'total_tokens': 33, 'completion_time': 0.09374854, 'prompt_time': 0.000436876, 'queue_time': 0.25564020000000004, 'total_time': 0.094185416}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-cfd37924-ff95-4d10-8e90-3a35e50cf87a-0', usage_metadata={'input_tokens': 15, 'output_tokens': 18, 'total_tokens': 33})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(\"Halo nama saya David\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Apa kabar? Bahasa Indonesia! \"Apa kabar\" is a common Indonesian greeting that means \"How are you?\" in English.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 15, 'total_tokens': 46, 'completion_time': 0.130648644, 'prompt_time': 0.000297987, 'queue_time': 0.247550529, 'total_time': 0.130946631}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-38a04cd5-3b1e-41d4-bd5b-f84e8c724ece-0', usage_metadata={'input_tokens': 15, 'output_tokens': 31, 'total_tokens': 46})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(\"Apa kabar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm happy to chat with you, but I don't know your name because we just started our conversation! Would you like to introduce yourself?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 15, 'total_tokens': 45, 'completion_time': 0.137717245, 'prompt_time': 0.000302817, 'queue_time': 0.24878447799999998, 'total_time': 0.138020062}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-04fa763e-6eaf-41e0-b724-968c7ba90496-0', usage_metadata={'input_tokens': 15, 'output_tokens': 30, 'total_tokens': 45})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_groq.invoke(\"Siapa nama saya?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LangGraph Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_groq = ChatGroq(model=model)\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm_groq.invoke(state[\"messages\"])\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Siapa nama saya?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Nama saya adalah David', additional_kwargs={}, response_metadata={}, id='6b6346dd-7567-4517-8faf-5827bf4030a1'),\n",
       "  AIMessage(content='Selamat datang, David! Senang berkenalan denganmu. Apa yang ingin kamu bicarakan hari ini?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 14, 'total_tokens': 41, 'completion_time': 0.083155303, 'prompt_time': 0.000247997, 'queue_time': 0.247440299, 'total_time': 0.0834033}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-9b43ae24-a202-4dfd-9eac-ca0cda8a7513-0', usage_metadata={'input_tokens': 14, 'output_tokens': 27, 'total_tokens': 41}),\n",
       "  HumanMessage(content='Siapa nama saya?', additional_kwargs={}, response_metadata={}, id='a1890ff9-1d0b-4cc8-8b5d-ead5d1f911d7'),\n",
       "  AIMessage(content='Nama kamu adalah David!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 55, 'total_tokens': 61, 'completion_time': 0.046275342, 'prompt_time': 0.001472944, 'queue_time': 0.24715781, 'total_time': 0.047748286}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-0c635fbf-8f3d-47ce-a732-0a2fa1a5b70a-0', usage_metadata={'input_tokens': 55, 'output_tokens': 6, 'total_tokens': 61}),\n",
       "  HumanMessage(content='Siapa nama saya?', additional_kwargs={}, response_metadata={}, id='ec467764-c77d-4619-bffe-ca768a35ad75'),\n",
       "  AIMessage(content='Nama kamu adalah David, kan?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 75, 'total_tokens': 83, 'completion_time': 0.04764093, 'prompt_time': 0.002126748, 'queue_time': 0.24791798799999998, 'total_time': 0.049767678}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-7142f751-8089-4ec8-968f-cd6dba602c08-0', usage_metadata={'input_tokens': 75, 'output_tokens': 8, 'total_tokens': 83})]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
